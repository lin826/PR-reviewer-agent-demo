diff --git a/xarray/core/common.py b/xarray/core/common.py
index 3c328f42..a8d6fe2b 100644
--- a/xarray/core/common.py
+++ b/xarray/core/common.py
@@ -2021,18 +2021,46 @@ def get_chunksizes(
     variables: Iterable[Variable],
 ) -> Mapping[Any, tuple[int, ...]]:
 
     chunks: dict[Any, tuple[int, ...]] = {}
     for v in variables:
-        if hasattr(v.data, "chunks"):
+        # Check if we can get chunk information without loading data
+        # This is important for zarr-backed arrays where accessing .data loads everything
+        if hasattr(v._data, "chunks"):
+            # This is a dask array, we can safely access chunks
             for dim, c in v.chunksizes.items():
                 if dim in chunks and c != chunks[dim]:
                     raise ValueError(
                         f"Object has inconsistent chunks along dimension {dim}. "
                         "This can be fixed by calling unify_chunks()."
                     )
                 chunks[dim] = c
+        else:
+            # Check if chunk information is available in encoding (for zarr-backed arrays)
+            # Only use this if the data is still lazy (not loaded)
+            preferred_chunks = v.encoding.get("preferred_chunks", {})
+            if preferred_chunks and not v._in_memory:
+                for dim, chunk_size in preferred_chunks.items():
+                    if isinstance(chunk_size, int):
+                        # Convert single chunk size to tuple of chunk sizes
+                        dim_size = v.sizes.get(dim, 0)
+                        if dim_size > 0:
+                            num_chunks = (dim_size + chunk_size - 1) // chunk_size
+                            chunk_tuple = tuple(
+                                chunk_size if i < num_chunks - 1 else dim_size - i * chunk_size
+                                for i in range(num_chunks)
+                            )
+                            # Only add if not already present or if this is a multi-dimensional variable
+                            # (prioritize data variables over coordinate variables)
+                            if dim not in chunks or len(v.dims) > 1:
+                                chunks[dim] = chunk_tuple
+                    elif hasattr(chunk_size, "__iter__"):
+                        # chunk_size is already a sequence of chunk sizes
+                        chunk_tuple = tuple(chunk_size)
+                        # Only add if not already present or if this is a multi-dimensional variable
+                        if dim not in chunks or len(v.dims) > 1:
+                            chunks[dim] = chunk_tuple
     return Frozen(chunks)
 
 
 def is_np_datetime_like(dtype: DTypeLike) -> bool:
     """Check if a dtype is a subclass of the numpy datetime types"""
diff --git a/xarray/core/variable.py b/xarray/core/variable.py
index 2d115ff0..0d0b1c1e 100644
--- a/xarray/core/variable.py
+++ b/xarray/core/variable.py
@@ -1012,14 +1012,37 @@ class Variable(AbstractArray, NdimSizeLenMixin, VariableArithmetic):
         --------
         Variable.chunk
         Variable.chunks
         xarray.unify_chunks
         """
+        # Check if we can get chunk information without loading data
         if hasattr(self._data, "chunks"):
+            # This is a dask array, we can safely access chunks
             return Frozen({dim: c for dim, c in zip(self.dims, self.data.chunks)})
         else:
-            return {}
+            # Check if chunk information is available in encoding (for zarr-backed arrays)
+            # Only use this if the data is still lazy (not loaded)
+            preferred_chunks = self.encoding.get("preferred_chunks", {})
+            if preferred_chunks and not self._in_memory:
+                chunks = {}
+                for dim, chunk_size in preferred_chunks.items():
+                    if isinstance(chunk_size, int):
+                        # Convert single chunk size to tuple of chunk sizes
+                        dim_size = self.sizes.get(dim, 0)
+                        if dim_size > 0:
+                            num_chunks = (dim_size + chunk_size - 1) // chunk_size
+                            chunk_tuple = tuple(
+                                chunk_size if i < num_chunks - 1 else dim_size - i * chunk_size
+                                for i in range(num_chunks)
+                            )
+                            chunks[dim] = chunk_tuple
+                    elif hasattr(chunk_size, "__iter__"):
+                        # chunk_size is already a sequence of chunk sizes
+                        chunks[dim] = tuple(chunk_size)
+                return Frozen(chunks)
+            else:
+                return {}
 
     _array_counter = itertools.count()
 
     def chunk(
         self,
