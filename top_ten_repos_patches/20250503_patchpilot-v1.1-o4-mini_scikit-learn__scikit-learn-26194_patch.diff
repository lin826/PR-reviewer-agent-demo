diff --git a/sklearn/metrics/_ranking.py b/sklearn/metrics/_ranking.py
index 0cdead923..f8653ed04 100644
--- a/sklearn/metrics/_ranking.py
+++ b/sklearn/metrics/_ranking.py
@@ -1018,8 +1018,12 @@ def roc_curve(
 
     thresholds : ndarray of shape = (n_thresholds,)
         Decreasing thresholds on the decision function used to compute
+
         fpr and tpr. `thresholds[0]` represents no instances being predicted
-        and is arbitrarily set to `max(y_score) + 1`.
+        and is arbitrarily set to a value strictly greater than `max(y_score)` (for
+        floating-point scores this is the next representable float larger than
+        `max(y_score)`).
+
 
     See Also
     --------
@@ -1082,8 +1086,21 @@ def roc_curve(
     # Add an extra threshold position
     # to make sure that the curve starts at (0, 0)
     tps = np.r_[0, tps]
+
     fps = np.r_[0, fps]
-    thresholds = np.r_[thresholds[0] + 1, thresholds]
+
+    if np.issubdtype(thresholds.dtype, np.floating):
+        if thresholds[0] < 1.0:
+            # probabilityâ€‘like scores (<1): stay within [0,1]
+            first_thr = np.nextafter(thresholds[0], np.inf)
+        else:
+            # keep historical behaviour for scores that already reach 1
+            first_thr = thresholds[0] + 1.0
+    else:
+        first_thr = thresholds[0] + 1
+
+    thresholds = np.r_[first_thr, thresholds]
+
 
     if fps[-1] <= 0:
         warnings.warn(
@@ -1952,4 +1969,4 @@ def top_k_accuracy_score(
     elif sample_weight is None:
         return np.sum(hits)
     else:
-        return np.dot(hits, sample_weight)
+        return np.dot(hits, sample_weight)
