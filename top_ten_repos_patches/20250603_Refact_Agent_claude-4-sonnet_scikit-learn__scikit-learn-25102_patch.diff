diff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py
index 335773c6a..908d387dd 100644
--- a/sklearn/utils/_set_output.py
+++ b/sklearn/utils/_set_output.py
@@ -12,6 +12,7 @@ def _wrap_in_pandas_container(
     *,
     columns,
     index=None,
+    dtypes=None,
 ):
     """Create a Pandas DataFrame.
 
@@ -36,6 +37,11 @@ def _wrap_in_pandas_container(
     index : array-like, default=None
         Index for data.
 
+    dtypes : dict, Series, or None, default=None
+        Dictionary or Series mapping column names to dtypes. If provided,
+        the resulting DataFrame will have these dtypes applied to preserve
+        the original column types.
+
     Returns
     -------
     dataframe : DataFrame
@@ -57,9 +63,35 @@ def _wrap_in_pandas_container(
             data_to_wrap.columns = columns
         if index is not None:
             data_to_wrap.index = index
+        # Apply dtypes if provided
+        if dtypes is not None:
+            # Only apply dtypes for columns that exist in both the DataFrame and dtypes
+            common_columns = set(data_to_wrap.columns) & set(dtypes.keys())
+            if common_columns:
+                dtypes_to_apply = {col: dtypes[col] for col in common_columns}
+                try:
+                    data_to_wrap = data_to_wrap.astype(dtypes_to_apply)
+                except (ValueError, TypeError):
+                    # If dtype conversion fails, continue without applying dtypes
+                    pass
         return data_to_wrap
 
-    return pd.DataFrame(data_to_wrap, index=index, columns=columns)
+    df = pd.DataFrame(data_to_wrap, index=index, columns=columns)
+    
+    # Apply dtypes if provided
+    if dtypes is not None and columns is not None:
+        # Only apply dtypes for columns that exist in both the DataFrame and dtypes
+        if hasattr(columns, '__iter__') and not isinstance(columns, str):
+            common_columns = set(columns) & set(dtypes.keys())
+            if common_columns:
+                dtypes_to_apply = {col: dtypes[col] for col in common_columns}
+                try:
+                    df = df.astype(dtypes_to_apply)
+                except (ValueError, TypeError):
+                    # If dtype conversion fails, continue without applying dtypes
+                    pass
+    
+    return df
 
 
 def _get_output_config(method, estimator=None):
@@ -127,10 +159,17 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):
         return data_to_wrap
 
     # dense_config == "pandas"
+    # Capture original dtypes if input is a pandas DataFrame
+    original_dtypes = None
+    pd = check_pandas_support("Setting output container to 'pandas'")
+    if isinstance(original_input, pd.DataFrame):
+        original_dtypes = original_input.dtypes.to_dict()
+    
     return _wrap_in_pandas_container(
         data_to_wrap=data_to_wrap,
         index=getattr(original_input, "index", None),
         columns=estimator.get_feature_names_out,
+        dtypes=original_dtypes,
     )
 
 
diff --git a/sklearn/utils/tests/test_set_output.py b/sklearn/utils/tests/test_set_output.py
index ac73ca094..6cb4f93d9 100644
--- a/sklearn/utils/tests/test_set_output.py
+++ b/sklearn/utils/tests/test_set_output.py
@@ -260,3 +260,106 @@ def test_set_output_mro():
         pass
 
     assert C().transform(None) == "B"
+
+
+def test__wrap_in_pandas_container_preserve_dtypes():
+    """Check that _wrap_in_pandas_container preserves dtypes when provided."""
+    pd = pytest.importorskip("pandas")
+    
+    # Test with numpy array and dtypes
+    X = np.asarray([[1.0, 2.0], [3.0, 4.0]])
+    columns = ["col1", "col2"]
+    dtypes = {"col1": "float32", "col2": "int64"}
+    
+    result = _wrap_in_pandas_container(X, columns=columns, dtypes=dtypes)
+    assert isinstance(result, pd.DataFrame)
+    assert result.dtypes["col1"] == "float32"
+    assert result.dtypes["col2"] == "int64"
+    
+    # Test with DataFrame and dtypes
+    X_df = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]], columns=["col1", "col2"])
+    dtypes = {"col1": "float16", "col2": "category"}
+    
+    result = _wrap_in_pandas_container(X_df, columns=None, dtypes=dtypes)
+    assert isinstance(result, pd.DataFrame)
+    assert result.dtypes["col1"] == "float16"
+    assert result.dtypes["col2"] == "category"
+
+
+def test__wrap_in_pandas_container_partial_dtypes():
+    """Check that _wrap_in_pandas_container handles partial dtype mappings."""
+    pd = pytest.importorskip("pandas")
+    
+    X = np.asarray([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
+    columns = ["col1", "col2", "col3"]
+    # Only provide dtypes for some columns
+    dtypes = {"col1": "float32", "col3": "int32"}
+    
+    result = _wrap_in_pandas_container(X, columns=columns, dtypes=dtypes)
+    assert isinstance(result, pd.DataFrame)
+    assert result.dtypes["col1"] == "float32"
+    assert result.dtypes["col2"] == "float64"  # default
+    assert result.dtypes["col3"] == "int32"
+
+
+def test__wrap_in_pandas_container_invalid_dtypes():
+    """Check that _wrap_in_pandas_container handles invalid dtypes gracefully."""
+    pd = pytest.importorskip("pandas")
+    
+    X = np.asarray([["a", "b"], ["c", "d"]])  # string data
+    columns = ["col1", "col2"]
+    # Try to apply numeric dtypes to string data
+    dtypes = {"col1": "float32", "col2": "int64"}
+    
+    # Should not raise an error, just ignore invalid dtypes
+    result = _wrap_in_pandas_container(X, columns=columns, dtypes=dtypes)
+    assert isinstance(result, pd.DataFrame)
+    # Should keep original dtypes when conversion fails
+    assert result.dtypes["col1"] == "object"
+    assert result.dtypes["col2"] == "object"
+
+
+def test_dtype_preservation_with_estimator():
+    """Test dtype preservation with a real estimator using pandas output."""
+    pd = pytest.importorskip("pandas")
+    
+    # Create test data with mixed dtypes
+    X_df = pd.DataFrame({
+        "float16_col": np.array([1.0, 2.0, 3.0], dtype="float16"),
+        "float32_col": np.array([4.0, 5.0, 6.0], dtype="float32"),
+        "category_col": pd.Categorical(["a", "b", "c"]),
+        "int32_col": np.array([7, 8, 9], dtype="int32")
+    })
+    
+    # Create a simple estimator that preserves all columns
+    class IdentityTransformer(_SetOutputMixin):
+        def fit(self, X, y=None):
+            self.n_features_in_ = X.shape[1]
+            if hasattr(X, 'columns'):
+                self.feature_names_in_ = X.columns.tolist()
+            return self
+        
+        def transform(self, X, y=None):
+            # Return the same data (identity transformation)
+            return X.values if hasattr(X, 'values') else X
+        
+        def get_feature_names_out(self, input_features=None):
+            if hasattr(self, 'feature_names_in_'):
+                return np.asarray(self.feature_names_in_, dtype=object)
+            if input_features is not None:
+                return np.asarray(input_features, dtype=object)
+            return np.array([f"feature_{i}" for i in range(self.n_features_in_)])
+    
+    # Test with pandas output
+    transformer = IdentityTransformer()
+    transformer.set_output(transform="pandas")
+    transformer.fit(X_df)
+    
+    # Transform and check dtypes are preserved
+    X_transformed = transformer.transform(X_df)
+    
+    assert isinstance(X_transformed, pd.DataFrame)
+    assert X_transformed.dtypes["float16_col"] == "float16"
+    assert X_transformed.dtypes["float32_col"] == "float32"
+    assert X_transformed.dtypes["category_col"] == "category"
+    assert X_transformed.dtypes["int32_col"] == "int32"
