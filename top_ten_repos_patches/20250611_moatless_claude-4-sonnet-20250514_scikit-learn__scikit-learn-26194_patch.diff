--- a/sklearn/metrics/_ranking.py
+++ b/sklearn/metrics/_ranking.py
@@ -1019,7 +1019,8 @@
     thresholds : ndarray of shape = (n_thresholds,)
         Decreasing thresholds on the decision function used to compute
         fpr and tpr. `thresholds[0]` represents no instances being predicted
-        and is arbitrarily set to `max(y_score) + 1`.
+        and is arbitrarily set to `max(y_score) + 1` for general decision scores.
+        For probability estimates (when max(y_score) < 1), it is capped at 1.0.
 
     See Also
     --------
@@ -1061,6 +1062,11 @@
     fps, tps, thresholds = _binary_clf_curve(
         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight
     )
+    
+    # Check if y_score appears to be probability estimates
+    # Only apply the fix when max(y_score) < 1, indicating likely probability estimates
+    y_score_array = np.asarray(y_score)
+    is_probability_estimates = np.all(y_score_array >= 0) and np.max(y_score_array) < 1.0
 
     # Attempt to drop thresholds corresponding to points in between and
     # collinear with other points. These are always suboptimal and do not
@@ -1083,7 +1089,12 @@
     # to make sure that the curve starts at (0, 0)
     tps = np.r_[0, tps]
     fps = np.r_[0, fps]
-    thresholds = np.r_[thresholds[0] + 1, thresholds]
+    # When y_score appears to be probability estimates (all values in [0,1]), 
+    # cap the additional threshold at 1.0 to avoid thresholds > 1
+    if is_probability_estimates:
+        thresholds = np.r_[1.0, thresholds]
+    else:
+        thresholds = np.r_[thresholds[0] + 1, thresholds]
 
     if fps[-1] <= 0:
         warnings.warn(
