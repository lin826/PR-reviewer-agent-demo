diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py
index 99d6096af..5db976539 100644
--- a/sklearn/model_selection/_search.py
+++ b/sklearn/model_selection/_search.py
@@ -17,6 +17,7 @@ from collections import Mapping, namedtuple, defaultdict, Sequence, Iterable
 from functools import partial, reduce
 from itertools import product
 import operator
+import time
 import warnings
 
 import numpy as np
@@ -764,12 +765,18 @@ class BaseSearchCV(six.with_metaclass(ABCMeta, BaseEstimator,
                 self.best_index_]
 
         if self.refit:
+            # Start timing the refit process
+            refit_start_time = time.time()
+            
             self.best_estimator_ = clone(base_estimator).set_params(
                 **self.best_params_)
             if y is not None:
                 self.best_estimator_.fit(X, y, **fit_params)
             else:
                 self.best_estimator_.fit(X, **fit_params)
+            
+            # End timing and store refit_time_
+            self.refit_time_ = time.time() - refit_start_time
 
         # Store the only scorer not as a dict for single metric evaluation
         self.scorer_ = scorers if self.multimetric_ else scorers['score']
diff --git a/sklearn/model_selection/tests/test_search.py b/sklearn/model_selection/tests/test_search.py
index f436c7b55..0952e108c 100644
--- a/sklearn/model_selection/tests/test_search.py
+++ b/sklearn/model_selection/tests/test_search.py
@@ -67,7 +67,8 @@ from sklearn.metrics import make_scorer
 from sklearn.metrics import roc_auc_score
 from sklearn.impute import SimpleImputer
 from sklearn.pipeline import Pipeline
-from sklearn.linear_model import Ridge, SGDClassifier
+from sklearn.linear_model import Ridge, SGDClassifier, LogisticRegression
+from sklearn.ensemble import RandomForestClassifier
 
 from sklearn.model_selection.tests.common import OneTimeSplitter
 
@@ -1173,6 +1174,67 @@ def test_search_cv_timing():
             assert_true(np.all(search.cv_results_[key] < 1))
 
 
+def test_search_cv_refit_time():
+    """Test that refit_time_ attribute is properly set and reasonable."""
+    # Create a small dataset
+    X, y = make_classification(n_samples=50, n_features=4, n_classes=2, 
+                               random_state=42)
+    
+    # Test GridSearchCV with refit=True
+    gs = GridSearchCV(
+        RandomForestClassifier(random_state=42),
+        param_grid={'n_estimators': [5, 10]},
+        cv=2,
+        refit=True
+    )
+    gs.fit(X, y)
+    
+    # Check that refit_time_ exists and is reasonable
+    assert_true(hasattr(gs, 'refit_time_'))
+    assert_true(gs.refit_time_ >= 0)
+    assert_true(gs.refit_time_ < 10)  # Should be reasonable for small dataset
+    
+    # Test RandomizedSearchCV with refit=True
+    rs = RandomizedSearchCV(
+        RandomForestClassifier(random_state=42),
+        param_distributions={'n_estimators': [5, 10, 15]},
+        n_iter=2,
+        cv=2,
+        refit=True,
+        random_state=42
+    )
+    rs.fit(X, y)
+    
+    # Check that refit_time_ exists and is reasonable
+    assert_true(hasattr(rs, 'refit_time_'))
+    assert_true(rs.refit_time_ >= 0)
+    assert_true(rs.refit_time_ < 10)  # Should be reasonable for small dataset
+    
+    # Test with refit=False - refit_time_ should not exist
+    gs_no_refit = GridSearchCV(
+        RandomForestClassifier(random_state=42),
+        param_grid={'n_estimators': [5, 10]},
+        cv=2,
+        refit=False
+    )
+    gs_no_refit.fit(X, y)
+    
+    assert_false(hasattr(gs_no_refit, 'refit_time_'))
+    
+    # Test multi-metric scoring with refit
+    gs_multi = GridSearchCV(
+        LogisticRegression(random_state=42, max_iter=1000),
+        param_grid={'C': [0.1, 1.0]},
+        cv=2,
+        scoring=['accuracy', 'f1'],
+        refit='accuracy'
+    )
+    gs_multi.fit(X, y)
+    
+    assert_true(hasattr(gs_multi, 'refit_time_'))
+    assert_true(gs_multi.refit_time_ >= 0)
+
+
 def test_grid_search_correct_score_results():
     # test that correct scores are used
     n_splits = 3
