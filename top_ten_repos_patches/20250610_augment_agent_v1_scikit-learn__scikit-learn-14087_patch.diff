diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py
index 1999f1dae..998b0f8fc 100644
--- a/sklearn/linear_model/logistic.py
+++ b/sklearn/linear_model/logistic.py
@@ -2168,22 +2168,27 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,
 
             else:
                 # Take the best scores across every fold and the average of
                 # all coefficients corresponding to the best scores.
                 best_indices = np.argmax(scores, axis=1)
-                if self.multi_class == 'ovr':
+                if multi_class == 'ovr':
                     w = np.mean([coefs_paths[i, best_indices[i], :]
                                  for i in range(len(folds))], axis=0)
                 else:
                     w = np.mean([coefs_paths[:, i, best_indices[i], :]
                                  for i in range(len(folds))], axis=0)
 
                 best_indices_C = best_indices % len(self.Cs_)
                 self.C_.append(np.mean(self.Cs_[best_indices_C]))
 
                 best_indices_l1 = best_indices // len(self.Cs_)
-                self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))
+                l1_ratios_array = np.asarray(l1_ratios_)
+                if l1_ratios_array[0] is None:
+                    # When penalty is not 'elasticnet', l1_ratios_ is [None]
+                    self.l1_ratio_.append(None)
+                else:
+                    self.l1_ratio_.append(np.mean(l1_ratios_array[best_indices_l1]))
 
             if multi_class == 'multinomial':
                 self.C_ = np.tile(self.C_, n_classes)
                 self.l1_ratio_ = np.tile(self.l1_ratio_, n_classes)
                 self.coef_ = w[:, :X.shape[1]]
