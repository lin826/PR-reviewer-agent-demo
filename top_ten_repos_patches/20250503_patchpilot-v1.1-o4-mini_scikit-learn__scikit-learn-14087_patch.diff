diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py
index 1999f1dae..651f5515f 100644
--- a/sklearn/linear_model/logistic.py
+++ b/sklearn/linear_model/logistic.py
@@ -2170,18 +2170,22 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,
                 # Take the best scores across every fold and the average of
                 # all coefficients corresponding to the best scores.
                 best_indices = np.argmax(scores, axis=1)
-                if self.multi_class == 'ovr':
+
+                if multi_class == 'ovr':
                     w = np.mean([coefs_paths[i, best_indices[i], :]
+
                                  for i in range(len(folds))], axis=0)
                 else:
                     w = np.mean([coefs_paths[:, i, best_indices[i], :]
                                  for i in range(len(folds))], axis=0)
 
+
                 best_indices_C = best_indices % len(self.Cs_)
                 self.C_.append(np.mean(self.Cs_[best_indices_C]))
 
                 best_indices_l1 = best_indices // len(self.Cs_)
-                self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))
+                self.l1_ratio_.append(None if self.penalty != 'elasticnet' else np.mean(np.asarray(l1_ratios_)[best_indices_l1]))
+
 
             if multi_class == 'multinomial':
                 self.C_ = np.tile(self.C_, n_classes)
@@ -2243,4 +2247,4 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,
         if isinstance(scoring, str):
             scoring = get_scorer(scoring)
 
-        return scoring(self, X, y, sample_weight=sample_weight)
+        return scoring(self, X, y, sample_weight=sample_weight)
