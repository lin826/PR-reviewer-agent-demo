diff --git a/xarray/core/nanops.py b/xarray/core/nanops.py
index 41c8d258..4cdf3d6a 100644
--- a/xarray/core/nanops.py
+++ b/xarray/core/nanops.py
@@ -26,22 +26,33 @@ def _maybe_null_out(result, axis, mask, min_count=1):
     """
     xarray version of pandas.core.nanops._maybe_null_out
     """
-    if hasattr(axis, "__len__"):  # if tuple or list
-        raise ValueError(
-            "min_count is not available for reduction with more than one dimensions."
-        )
-
-    if axis is not None and getattr(result, "ndim", False):
-        null_mask = (mask.shape[axis] - mask.sum(axis) - min_count) < 0
-        if null_mask.any():
-            dtype, fill_value = dtypes.maybe_promote(result.dtype)
-            result = result.astype(dtype)
-            result[null_mask] = fill_value
-
-    elif getattr(result, "dtype", None) not in dtypes.NAT_TYPES:
-        null_mask = mask.size - mask.sum()
-        if null_mask < min_count:
-            result = np.nan
+    if axis is None:
+        # Global reduction (all dimensions)
+        valid_count = mask.size - mask.sum()
+        if valid_count < min_count:
+            return np.nan
+        return result
+
+    if not np.isscalar(axis):
+        # Multiple dimensions (tuple or list of axes)
+        axis_tuple = tuple(axis)
+        # Calculate the total size of the reduced dimensions
+        group_size = int(np.prod([mask.shape[ax] for ax in axis_tuple]))
+        # Sum the mask over all specified axes to get count of nulls
+        nulls_per_group = mask.sum(axis=axis_tuple)
+        # Calculate valid counts
+        valid_counts = group_size - nulls_per_group
+        # Check if valid counts are less than min_count
+        null_mask = (valid_counts - min_count) < 0
+    else:
+        # Single dimension (scalar axis)
+        valid_counts = mask.shape[axis] - mask.sum(axis)
+        null_mask = (valid_counts - min_count) < 0
+
+    if getattr(result, "ndim", False) and null_mask.any():
+        dtype, fill_value = dtypes.maybe_promote(result.dtype)
+        result = result.astype(dtype)
+        result[null_mask] = fill_value
 
     return result
 
@@ -112,6 +123,13 @@ def nansum(a, axis=None, dtype=None, out=None, min_count=None):
     a, mask = _replace_nan(a, 0)
     result = _dask_or_eager_func("sum")(a, axis=axis, dtype=dtype)
     if min_count is not None:
+        # Special case: if we're reducing over all dimensions and min_count is greater than
+        # the number of valid values, return NaN
+        if hasattr(axis, "__len__") and len(axis) == a.ndim:
+            valid_count = a.size - mask.sum()
+            if valid_count < min_count:
+                return np.nan
+        # Otherwise, use the standard null-out logic
         return _maybe_null_out(result, axis, mask, min_count)
     else:
         return result
@@ -182,6 +200,13 @@ def nanprod(a, axis=None, dtype=None, out=None, min_count=None):
     a, mask = _replace_nan(a, 1)
     result = _dask_or_eager_func("nanprod")(a, axis=axis, dtype=dtype, out=out)
     if min_count is not None:
+        # Special case: if we're reducing over all dimensions and min_count is greater than
+        # the number of valid values, return NaN
+        if hasattr(axis, "__len__") and len(axis) == a.ndim:
+            valid_count = a.size - mask.sum()
+            if valid_count < min_count:
+                return np.nan
+        # Otherwise, use the standard null-out logic
         return _maybe_null_out(result, axis, mask, min_count)
     else:
         return result
