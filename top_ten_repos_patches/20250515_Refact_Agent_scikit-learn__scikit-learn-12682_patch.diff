diff --git a/examples/decomposition/plot_sparse_coding.py b/examples/decomposition/plot_sparse_coding.py
index 528817ad0..5556b97d2 100644
--- a/examples/decomposition/plot_sparse_coding.py
+++ b/examples/decomposition/plot_sparse_coding.py
@@ -65,7 +65,8 @@ y[np.logical_not(first_quarter)] = -1.
 # (title, transform_algorithm, transform_alpha,
 #  transform_n_nozero_coefs, color)
 estimators = [('OMP', 'omp', None, 15, 'navy'),
-              ('Lasso', 'lasso_lars', 2, None, 'turquoise'), ]
+              ('Lasso', 'lasso_lars', 2, None, 'turquoise'),
+              ('Lasso CD', 'lasso_cd', 2, None, 'red'), ]
 lw = 2
 # Avoid FutureWarning about default value change when numpy >= 1.14
 lstsq_rcond = None if LooseVersion(np.__version__) >= '1.14' else -1
@@ -78,9 +79,19 @@ for subplot, (D, title) in enumerate(zip((D_fixed, D_multi),
     plt.plot(y, lw=lw, linestyle='--', label='Original signal')
     # Do a wavelet approximation
     for title, algo, alpha, n_nonzero, color in estimators:
-        coder = SparseCoder(dictionary=D, transform_n_nonzero_coefs=n_nonzero,
-                            transform_alpha=alpha, transform_algorithm=algo)
-        x = coder.transform(y.reshape(1, -1))
+        if callable(algo):
+            # Use custom sparse_encode function directly
+            x = algo(y.reshape(1, -1), D, alpha=alpha, n_nonzero_coefs=n_nonzero)
+        else:
+            # Use SparseCoder with algorithm name
+            transform_max_iter = 5000 if algo == 'lasso_cd' else None
+            coder = SparseCoder(dictionary=D, 
+                                transform_n_nonzero_coefs=n_nonzero,
+                                transform_alpha=alpha, 
+                                transform_algorithm=algo,
+                                transform_max_iter=transform_max_iter)
+            x = coder.transform(y.reshape(1, -1))
+            
         density = len(np.flatnonzero(x))
         x = np.ravel(np.dot(x, D))
         squared_error = np.sum((y - x) ** 2)
diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index a318c957f..591f40a9e 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -862,10 +862,11 @@ class SparseCodingMixin(TransformerMixin):
     """Sparse coding mixin"""
 
     def _set_sparse_coding_params(self, n_components,
-                                  transform_algorithm='omp',
-                                  transform_n_nonzero_coefs=None,
-                                  transform_alpha=None, split_sign=False,
-                                  n_jobs=None, positive_code=False):
+                                   transform_algorithm='omp',
+                                   transform_n_nonzero_coefs=None,
+                                   transform_alpha=None, split_sign=False,
+                                   n_jobs=None, positive_code=False,
+                                   transform_max_iter=None):
         self.n_components = n_components
         self.transform_algorithm = transform_algorithm
         self.transform_n_nonzero_coefs = transform_n_nonzero_coefs
@@ -873,6 +874,7 @@ class SparseCodingMixin(TransformerMixin):
         self.split_sign = split_sign
         self.n_jobs = n_jobs
         self.positive_code = positive_code
+        self.transform_max_iter = transform_max_iter
 
     def transform(self, X):
         """Encode the data as a sparse combination of the dictionary atoms.
@@ -896,11 +898,12 @@ class SparseCodingMixin(TransformerMixin):
 
         X = check_array(X)
 
+        max_iter = 1000 if self.transform_max_iter is None else self.transform_max_iter
         code = sparse_encode(
             X, self.components_, algorithm=self.transform_algorithm,
             n_nonzero_coefs=self.transform_n_nonzero_coefs,
             alpha=self.transform_alpha, n_jobs=self.n_jobs,
-            positive=self.positive_code)
+            max_iter=max_iter, positive=self.positive_code)
 
         if self.split_sign:
             # feature vector is split into a positive and negative side
@@ -974,6 +977,10 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
 
         .. versionadded:: 0.20
 
+    transform_max_iter : int, optional
+        Maximum number of iterations to perform if `algorithm='lasso_cd'`.
+        Default is 1000.
+
     Attributes
     ----------
     components_ : array, [n_components, n_features]
@@ -991,12 +998,13 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
 
     def __init__(self, dictionary, transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
-                 split_sign=False, n_jobs=None, positive_code=False):
+                 split_sign=False, n_jobs=None, positive_code=False,
+                 transform_max_iter=None):
         self._set_sparse_coding_params(dictionary.shape[0],
-                                       transform_algorithm,
-                                       transform_n_nonzero_coefs,
-                                       transform_alpha, split_sign, n_jobs,
-                                       positive_code)
+                                        transform_algorithm,
+                                        transform_n_nonzero_coefs,
+                                        transform_alpha, split_sign, n_jobs,
+                                        positive_code, transform_max_iter)
         self.components_ = dictionary
 
     def fit(self, X, y=None):
@@ -1122,6 +1130,10 @@ class DictionaryLearning(BaseEstimator, SparseCodingMixin):
 
         .. versionadded:: 0.20
 
+    transform_max_iter : int, optional
+        Maximum number of iterations to perform if `transform_algorithm='lasso_cd'`.
+        Default is 1000.
+
     Attributes
     ----------
     components_ : array, [n_components, n_features]
@@ -1152,12 +1164,13 @@ class DictionaryLearning(BaseEstimator, SparseCodingMixin):
                  transform_n_nonzero_coefs=None, transform_alpha=None,
                  n_jobs=None, code_init=None, dict_init=None, verbose=False,
                  split_sign=False, random_state=None,
-                 positive_code=False, positive_dict=False):
+                 positive_code=False, positive_dict=False,
+                 transform_max_iter=None):
 
         self._set_sparse_coding_params(n_components, transform_algorithm,
                                        transform_n_nonzero_coefs,
                                        transform_alpha, split_sign, n_jobs,
-                                       positive_code)
+                                       positive_code, transform_max_iter)
         self.alpha = alpha
         self.max_iter = max_iter
         self.tol = tol
@@ -1341,12 +1354,13 @@ class MiniBatchDictionaryLearning(BaseEstimator, SparseCodingMixin):
                  shuffle=True, dict_init=None, transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
                  verbose=False, split_sign=False, random_state=None,
-                 positive_code=False, positive_dict=False):
+                 positive_code=False, positive_dict=False,
+                 transform_max_iter=None):
 
         self._set_sparse_coding_params(n_components, transform_algorithm,
                                        transform_n_nonzero_coefs,
                                        transform_alpha, split_sign, n_jobs,
-                                       positive_code)
+                                       positive_code, transform_max_iter)
         self.alpha = alpha
         self.n_iter = n_iter
         self.fit_algorithm = fit_algorithm
