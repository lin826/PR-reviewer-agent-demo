diff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py
index b7fbdf7da..dc1a8dab0 100644
--- a/sklearn/cluster/k_means_.py
+++ b/sklearn/cluster/k_means_.py
@@ -292,6 +292,10 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',
         raise ValueError("Invalid number of initializations."
                          " n_init=%d must be bigger than zero." % n_init)
     random_state = check_random_state(random_state)
+    # Draw exactly n_init "init seeds" from the master RNG. This
+    # ensures that both serial and parallel branches consume the same RNG
+    # draws in the same order.
+    seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)
 
     if max_iter <= 0:
         raise ValueError('Number of iterations should be a positive number,'
@@ -361,39 +365,35 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',
         raise ValueError("Algorithm must be 'auto', 'full' or 'elkan', got"
                          " %s" % str(algorithm))
     if effective_n_jobs(n_jobs) == 1:
-        # For a single thread, less memory is needed if we just store one set
-        # of the best results (as opposed to one set per run per thread).
-        for it in range(n_init):
-            # run a k-means once
+        # Single-threaded: run each init with its own seed
+        for seed in seeds:
             labels, inertia, centers, n_iter_ = kmeans_single(
-                X, sample_weight, n_clusters, max_iter=max_iter, init=init,
+                X, sample_weight, n_clusters,
+                max_iter=max_iter, init=init,
                 verbose=verbose, precompute_distances=precompute_distances,
                 tol=tol, x_squared_norms=x_squared_norms,
-                random_state=random_state)
-            # determine if these results are the best so far
+                random_state=seed)
             if best_inertia is None or inertia < best_inertia:
                 best_labels = labels.copy()
                 best_centers = centers.copy()
                 best_inertia = inertia
                 best_n_iter = n_iter_
     else:
-        # parallelisation of k-means runs
-        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)
+        # Parallel initializations: identical seeds in the same order
         results = Parallel(n_jobs=n_jobs, verbose=0)(
-            delayed(kmeans_single)(X, sample_weight, n_clusters,
-                                   max_iter=max_iter, init=init,
-                                   verbose=verbose, tol=tol,
-                                   precompute_distances=precompute_distances,
-                                   x_squared_norms=x_squared_norms,
-                                   # Change seed to ensure variety
-                                   random_state=seed)
+            delayed(kmeans_single)(
+                X, sample_weight, n_clusters,
+                max_iter=max_iter, init=init,
+                verbose=verbose, tol=tol,
+                precompute_distances=precompute_distances,
+                x_squared_norms=x_squared_norms,
+                random_state=seed)
             for seed in seeds)
-        # Get results with the lowest inertia
-        labels, inertia, centers, n_iters = zip(*results)
-        best = np.argmin(inertia)
-        best_labels = labels[best]
-        best_inertia = inertia[best]
-        best_centers = centers[best]
+        labels_list, inertia_list, centers_list, n_iters = zip(*results)
+        best = np.argmin(inertia_list)
+        best_labels = labels_list[best]
+        best_inertia = inertia_list[best]
+        best_centers = centers_list[best]
         best_n_iter = n_iters[best]
 
     if not sp.issparse(X):
