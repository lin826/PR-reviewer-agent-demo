diff --git a/sklearn/feature_selection/_sequential.py b/sklearn/feature_selection/_sequential.py
index e983c55de..e9d434875 100644
--- a/sklearn/feature_selection/_sequential.py
+++ b/sklearn/feature_selection/_sequential.py
@@ -6,10 +6,13 @@ from numbers import Integral, Real
 import numpy as np
 
 import warnings
 
 from ._base import SelectorMixin
+from collections.abc import Iterable
+import numbers
+
 from ..base import BaseEstimator, MetaEstimatorMixin, clone
 from ..utils._param_validation import HasMethods, Hidden, Interval, StrOptions
 from ..utils._param_validation import RealNotInt
 from ..utils._tags import _safe_tags
 from ..utils.validation import check_is_fitted
@@ -257,10 +260,21 @@ class SequentialFeatureSelector(SelectorMixin, MetaEstimatorMixin, BaseEstimator
             self.n_features_to_select_ = int(n_features * self.n_features_to_select)
 
         if self.tol is not None and self.tol < 0 and self.direction == "forward":
             raise ValueError("tol must be positive when doing forward selection")
 
+        # If cv is an iterable but not a CV splitter object (doesn't have a split method)
+        # and not an integer or string, convert it to a list to ensure it can be reused
+        if (
+            isinstance(self.cv, Iterable) 
+            and not hasattr(self.cv, "split") 
+            and not isinstance(self.cv, (str, numbers.Integral))
+        ):
+            self._cv = list(self.cv)
+        else:
+            self._cv = self.cv
+
         cloned_estimator = clone(self.estimator)
 
         # the current mask corresponds to the set of features:
         # - that we have already *selected* if we do forward selection
         # - that we have already *excluded* if we do backward selection
@@ -297,21 +311,22 @@ class SequentialFeatureSelector(SelectorMixin, MetaEstimatorMixin, BaseEstimator
         # when doing forward selection (resp. backward selection).
         # Feature will be added if the current score and past score are greater
         # than tol when n_feature is auto,
         candidate_feature_indices = np.flatnonzero(~current_mask)
         scores = {}
+        
         for feature_idx in candidate_feature_indices:
             candidate_mask = current_mask.copy()
             candidate_mask[feature_idx] = True
             if self.direction == "backward":
                 candidate_mask = ~candidate_mask
             X_new = X[:, candidate_mask]
             scores[feature_idx] = cross_val_score(
                 estimator,
                 X_new,
                 y,
-                cv=self.cv,
+                cv=self._cv,
                 scoring=self.scoring,
                 n_jobs=self.n_jobs,
             ).mean()
         new_feature_idx = max(scores, key=lambda feature_idx: scores[feature_idx])
         return new_feature_idx, scores[new_feature_idx]
