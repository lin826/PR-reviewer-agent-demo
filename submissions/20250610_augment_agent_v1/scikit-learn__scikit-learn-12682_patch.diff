diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index a318c957f..534eea0a6 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -863,18 +863,20 @@ class SparseCodingMixin(TransformerMixin):
 
     def _set_sparse_coding_params(self, n_components,
                                   transform_algorithm='omp',
                                   transform_n_nonzero_coefs=None,
                                   transform_alpha=None, split_sign=False,
-                                  n_jobs=None, positive_code=False):
+                                  n_jobs=None, positive_code=False,
+                                  transform_max_iter=1000):
         self.n_components = n_components
         self.transform_algorithm = transform_algorithm
         self.transform_n_nonzero_coefs = transform_n_nonzero_coefs
         self.transform_alpha = transform_alpha
         self.split_sign = split_sign
         self.n_jobs = n_jobs
         self.positive_code = positive_code
+        self.transform_max_iter = transform_max_iter
 
     def transform(self, X):
         """Encode the data as a sparse combination of the dictionary atoms.
 
         Coding method is determined by the object parameter
@@ -898,11 +900,11 @@ class SparseCodingMixin(TransformerMixin):
 
         code = sparse_encode(
             X, self.components_, algorithm=self.transform_algorithm,
             n_nonzero_coefs=self.transform_n_nonzero_coefs,
             alpha=self.transform_alpha, n_jobs=self.n_jobs,
-            positive=self.positive_code)
+            positive=self.positive_code, max_iter=self.transform_max_iter)
 
         if self.split_sign:
             # feature vector is split into a positive and negative side
             n_samples, n_features = code.shape
             split_code = np.empty((n_samples, 2 * n_features))
@@ -972,10 +974,13 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
     positive_code : bool
         Whether to enforce positivity when finding the code.
 
         .. versionadded:: 0.20
 
+    transform_max_iter : int, default=1000
+        Maximum number of iterations to perform if `transform_algorithm='lasso_cd'`.
+
     Attributes
     ----------
     components_ : array, [n_components, n_features]
         The unchanged dictionary atoms
 
@@ -989,16 +994,17 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
     """
     _required_parameters = ["dictionary"]
 
     def __init__(self, dictionary, transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
-                 split_sign=False, n_jobs=None, positive_code=False):
+                 split_sign=False, n_jobs=None, positive_code=False,
+                 transform_max_iter=1000):
         self._set_sparse_coding_params(dictionary.shape[0],
                                        transform_algorithm,
                                        transform_n_nonzero_coefs,
                                        transform_alpha, split_sign, n_jobs,
-                                       positive_code)
+                                       positive_code, transform_max_iter)
         self.components_ = dictionary
 
     def fit(self, X, y=None):
         """Do nothing and return the estimator unchanged
 
@@ -1120,10 +1126,13 @@ class DictionaryLearning(BaseEstimator, SparseCodingMixin):
     positive_dict : bool
         Whether to enforce positivity when finding the dictionary
 
         .. versionadded:: 0.20
 
+    transform_max_iter : int, default=1000
+        Maximum number of iterations to perform if `transform_algorithm='lasso_cd'`.
+
     Attributes
     ----------
     components_ : array, [n_components, n_features]
         dictionary atoms extracted from the data
 
@@ -1150,16 +1159,17 @@ class DictionaryLearning(BaseEstimator, SparseCodingMixin):
     def __init__(self, n_components=None, alpha=1, max_iter=1000, tol=1e-8,
                  fit_algorithm='lars', transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
                  n_jobs=None, code_init=None, dict_init=None, verbose=False,
                  split_sign=False, random_state=None,
-                 positive_code=False, positive_dict=False):
+                 positive_code=False, positive_dict=False,
+                 transform_max_iter=1000):
 
         self._set_sparse_coding_params(n_components, transform_algorithm,
                                        transform_n_nonzero_coefs,
                                        transform_alpha, split_sign, n_jobs,
-                                       positive_code)
+                                       positive_code, transform_max_iter)
         self.alpha = alpha
         self.max_iter = max_iter
         self.tol = tol
         self.fit_algorithm = fit_algorithm
         self.code_init = code_init
@@ -1303,10 +1313,13 @@ class MiniBatchDictionaryLearning(BaseEstimator, SparseCodingMixin):
     positive_dict : bool
         Whether to enforce positivity when finding the dictionary.
 
         .. versionadded:: 0.20
 
+    transform_max_iter : int, default=1000
+        Maximum number of iterations to perform if `transform_algorithm='lasso_cd'`.
+
     Attributes
     ----------
     components_ : array, [n_components, n_features]
         components extracted from the data
 
@@ -1339,16 +1352,17 @@ class MiniBatchDictionaryLearning(BaseEstimator, SparseCodingMixin):
     def __init__(self, n_components=None, alpha=1, n_iter=1000,
                  fit_algorithm='lars', n_jobs=None, batch_size=3,
                  shuffle=True, dict_init=None, transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
                  verbose=False, split_sign=False, random_state=None,
-                 positive_code=False, positive_dict=False):
+                 positive_code=False, positive_dict=False,
+                 transform_max_iter=1000):
 
         self._set_sparse_coding_params(n_components, transform_algorithm,
                                        transform_n_nonzero_coefs,
                                        transform_alpha, split_sign, n_jobs,
-                                       positive_code)
+                                       positive_code, transform_max_iter)
         self.alpha = alpha
         self.n_iter = n_iter
         self.fit_algorithm = fit_algorithm
         self.dict_init = dict_init
         self.verbose = verbose
